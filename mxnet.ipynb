{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mxnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rBrlMrKzQQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdMOYzUXppmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsoNFpRzratZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import difflib\n",
        "import importlib\n",
        "import math\n",
        "import cv2 as cv2\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import gluonnlp as nlp\n",
        "import leven\n",
        "import matplotlib.patches as patches\n",
        "from skimage import transform as skimage_tf, exposure\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GMODVjlrfJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ocr.utils.expand_bounding_box import expand_bounding_box\n",
        "from ocr.utils.sclite_helper import ScliteHelper\n",
        "from ocr.utils.word_to_line import sort_bbs_line_by_line, crop_line_images\n",
        "from ocr.utils.iam_dataset import IAMDataset, resize_image, crop_image, crop_handwriting_page\n",
        "from ocr.utils.encoder_decoder import Denoiser, ALPHABET, encode_char, decode_char, EOS, BOS\n",
        "from ocr.utils.beam_search import ctcBeamSearch\n",
        "\n",
        "import ocr.utils.denoiser_utils\n",
        "import ocr.utils.beam_search\n",
        "\n",
        "importlib.reload(ocr.utils.denoiser_utils)\n",
        "from ocr.utils.denoiser_utils import SequenceGenerator\n",
        "\n",
        "importlib.reload(ocr.utils.beam_search)\n",
        "from ocr.utils.beam_search import ctcBeamSearch\n",
        "\n",
        "\n",
        "\n",
        "from ocr.paragraph_segmentation_dcnn import SegmentationNetwork, paragraph_segmentation_transform\n",
        "from ocr.word_and_line_segmentation import SSD as WordSegmentationNet, predict_bounding_boxes\n",
        "from ocr.handwriting_line_recognition import Network as HandwritingRecognitionNet, handwriting_recognition_transform\n",
        "from ocr.handwriting_line_recognition import decode as decoder_handwriting, alphabet_encoding\n",
        "ctx = mx.gpu(0) if mx.context.num_gpus() > 0 else mx.cpu()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIpdGo1KriR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0FT_KyL0z6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper functions\n",
        "def resize_image(image, desired_size):\n",
        "    ''' Helper function to resize an image while keeping the aspect ratio.\n",
        "    Parameter\n",
        "    ---------\n",
        "\n",
        "    image: np.array\n",
        "        The image to be resized.\n",
        "\n",
        "    desired_size: (int, int)\n",
        "        The (height, width) of the resized image\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "\n",
        "    image: np.array\n",
        "        The image of size = desired_size\n",
        "\n",
        "    bounding box: (int, int, int, int)\n",
        "        (x, y, w, h) in percentages of the resized image of the original\n",
        "    '''\n",
        "    size = image.shape[:2]\n",
        "    if size[0] > desired_size[0] or size[1] > desired_size[1]:\n",
        "        ratio_w = float(desired_size[0]) / size[0]\n",
        "        ratio_h = float(desired_size[1]) / size[1]\n",
        "        ratio = min(ratio_w, ratio_h)\n",
        "        new_size = tuple([int(x * ratio) for x in size])\n",
        "        image = cv2.resize(image, (new_size[1], new_size[0]))\n",
        "        size = image.shape\n",
        "\n",
        "    delta_w = max(0, desired_size[1] - size[1])\n",
        "    delta_h = max(0, desired_size[0] - size[0])\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    color = image[0][0]\n",
        "    if color < 230:\n",
        "        color = 230\n",
        "    image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=float(color))\n",
        "    crop_bb = (left / image.shape[1], top / image.shape[0], (image.shape[1] - right - left) / image.shape[1],\n",
        "               (image.shape[0] - bottom - top) / image.shape[0])\n",
        "    image[image > 230] = 255\n",
        "    return image, crop_bb\n",
        "\n",
        "\n",
        "# this function takes in the img file path\n",
        "def _pre_process_image(img_in, _parse_method):\n",
        "    im = cv2.imread(img_in, cv2.IMREAD_GRAYSCALE)\n",
        "    if np.size(im) == 1:  # skip if the image data is corrupt.\n",
        "        return None\n",
        "    # reduce the size of form images so that it can fit in memory.\n",
        "    if _parse_method in [\"form\", \"form_bb\"]:\n",
        "        im, _ = resize_image(im, MAX_IMAGE_SIZE_FORM)\n",
        "    if _parse_method == \"line\":\n",
        "        im, _ = resize_image(im, MAX_IMAGE_SIZE_LINE)\n",
        "    if _parse_method == \"word\":\n",
        "        im, _ = resize_image(im, MAX_IMAGE_SIZE_WORD)\n",
        "    img_arr = np.asarray(im)\n",
        "    return img_arr\n",
        "\n",
        "\n",
        "def get_arg_max(prob):\n",
        "    '''\n",
        "    The greedy algorithm convert the output of the handwriting recognition network\n",
        "    into strings.\n",
        "    '''\n",
        "    arg_max = prob.topk(axis=2).asnumpy()\n",
        "    return decoder_handwriting(arg_max)[0]\n",
        "\n",
        "\n",
        "def get_beam_search(prob, width=5):\n",
        "    possibilities = ctcBeamSearch(prob.softmax()[0].asnumpy(), alphabet_encoding, None, width)\n",
        "    return possibilities[0]\n",
        "\n",
        "\n",
        "def get_denoised(prob, ctc_bs=False):\n",
        "    if ctc_bs:  # Using ctc beam search before denoising yields only limited improvements a is very slow\n",
        "        text = get_beam_search(prob)\n",
        "    else:\n",
        "        text = get_arg_max(prob)\n",
        "    src_seq, src_valid_length = encode_char(text)\n",
        "    src_seq = mx.nd.array([src_seq], ctx=ctx)\n",
        "    src_valid_length = mx.nd.array(src_valid_length, ctx=ctx)\n",
        "    encoder_outputs, _ = denoiser.encode(src_seq, valid_length=src_valid_length)\n",
        "    states = denoiser.decoder.init_state_from_encoder(encoder_outputs,\n",
        "                                                      encoder_valid_length=src_valid_length)\n",
        "    inputs = mx.nd.full(shape=(1,), ctx=src_seq.context, dtype=np.float32, val=BOS)\n",
        "    output = generator.generate_sequences(inputs, states, text)\n",
        "    return output.strip()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6fZANHqJq7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load \n",
        "paragraph_segmentation_net = SegmentationNetwork(ctx=ctx)\n",
        "paragraph_segmentation_net.cnn.load_parameters(\"models/paragraph_segmentation2.params\", ctx=ctx)\n",
        "paragraph_segmentation_net.hybridize()\n",
        "\n",
        "word_segmentation_net = WordSegmentationNet(2, ctx=ctx)\n",
        "word_segmentation_net.load_parameters(\"models/word_segmentation2.params\")\n",
        "word_segmentation_net.hybridize()\n",
        "\n",
        "\n",
        "handwriting_line_recognition_net = HandwritingRecognitionNet(rnn_hidden_states=512,\n",
        "                                                            rnn_layers=2, ctx=ctx, max_seq_len=160)\n",
        "handwriting_line_recognition_net.load_parameters(\"models/handwriting_line8.params\", ctx=ctx)\n",
        "handwriting_line_recognition_net.hybridize()\n",
        "\n",
        "FEATURE_LEN = 150\n",
        "denoiser = Denoiser(alphabet_size=len(ALPHABET), max_src_length=FEATURE_LEN, max_tgt_length=FEATURE_LEN, num_heads=16, embed_size=256, num_layers=2)\n",
        "denoiser.load_parameters('models/denoiser2.params', ctx=ctx)\n",
        "\n",
        "denoiser.hybridize(static_alloc=True)\n",
        "\n",
        "ctx_nlp = mx.cpu(0)\n",
        "language_model, vocab = nlp.model.big_rnn_lm_2048_512(dataset_name='gbw', pretrained=True,ctx=ctx_nlp)\n",
        "moses_tokenizer = nlp.data.SacreMosesTokenizer()\n",
        "moses_detokenizer = nlp.data.SacreMosesDetokenizer()\n",
        "\n",
        "beam_sampler = nlp.model.BeamSearchSampler(beam_size=20,\n",
        "                                           decoder=denoiser.decode_logprob,\n",
        "                                           eos_id=EOS,\n",
        "                                           scorer=nlp.model.BeamSearchScorer(),\n",
        "                                           max_length=150)\n",
        "\n",
        "\n",
        "generator = SequenceGenerator(beam_sampler, language_model, vocab, ctx_nlp, moses_tokenizer, moses_detokenizer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdGYk4JrAJ2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_op(img_n,folder_path):\n",
        "  image_name = img_n.split('.')[0]\n",
        "  img_path = os.path.join(img_dir, img_n)\n",
        "  image = _pre_process_image(img_path, 'form')\n",
        "\n",
        "  form_size = (1120, 800)\n",
        "\n",
        "\n",
        "  predicted_bbs = []\n",
        "\n",
        "\n",
        "  resized_image = paragraph_segmentation_transform(image, form_size)\n",
        "  bb_predicted = paragraph_segmentation_net(resized_image.as_in_context(ctx))\n",
        "  bb_predicted = bb_predicted[0].asnumpy()\n",
        "  bb_predicted = expand_bounding_box(bb_predicted, expand_bb_scale_x=0.03,\n",
        "                                    expand_bb_scale_y=0.03)\n",
        "  predicted_bbs.append(bb_predicted)\n",
        "\n",
        "  (x, y, w, h) = bb_predicted\n",
        "  image_h, image_w = image.shape[-2:]\n",
        "  (x, y, w, h) = (x * image_w, y * image_h, w * image_w, h * image_h)\n",
        "  \n",
        "  segmented_paragraph_size = (700, 700)\n",
        "  paragraph_segmented_images = []\n",
        "\n",
        "  bb = predicted_bbs[0]\n",
        "  image = crop_handwriting_page(image, bb, image_size=segmented_paragraph_size)\n",
        "  paragraph_segmented_images.append(image)\n",
        "  \n",
        "\n",
        "  min_c = 0.1\n",
        "  overlap_thres = 0.1\n",
        "  topk = 600\n",
        "  predicted_words_bbs_array = []\n",
        "\n",
        "  for i, paragraph_segmented_image in enumerate(paragraph_segmented_images):\n",
        "      predicted_bb = predict_bounding_boxes(\n",
        "          word_segmentation_net, paragraph_segmented_image, min_c, overlap_thres, topk, ctx)\n",
        "\n",
        "      predicted_words_bbs_array.append(predicted_bb)\n",
        "      for j in range(predicted_bb.shape[0]):\n",
        "          (x, y, w, h) = predicted_bb[j]\n",
        "          image_h, image_w = paragraph_segmented_image.shape[-2:]\n",
        "          (x, y, w, h) = (x * image_w, y * image_h, w * image_w, h * image_h)\n",
        "\n",
        "  line_images_array = []\n",
        "\n",
        "  for i, paragraph_segmented_image in enumerate(paragraph_segmented_images):\n",
        "      predicted_bbs = predicted_words_bbs_array[i]\n",
        "      line_bbs = sort_bbs_line_by_line(predicted_bbs, y_overlap=0.4)\n",
        "      line_images = crop_line_images(paragraph_segmented_image, line_bbs)\n",
        "      line_images_array.append(line_images)\n",
        "\n",
        "      for line_bb in line_bbs:\n",
        "          (x, y, w, h) = line_bb\n",
        "          image_h, image_w = paragraph_segmented_image.shape[-2:]\n",
        "          (x, y, w, h) = (x * image_w, y * image_h, w * image_w, h * image_h)\n",
        "\n",
        "\n",
        "\n",
        "  line_image_size = (60, 800)\n",
        "  character_probs = []\n",
        "  for line_images in line_images_array:\n",
        "      form_character_prob = []\n",
        "      for i, line_image in enumerate(line_images):\n",
        "          line_image = handwriting_recognition_transform(line_image, line_image_size)\n",
        "          line_character_prob = handwriting_line_recognition_net(line_image.as_in_context(ctx))\n",
        "          form_character_prob.append(line_character_prob)\n",
        "      character_probs.append(form_character_prob)\n",
        "\n",
        "\n",
        "  FEATURE_LEN = 150\n",
        "  save_path = os.path.join(folder_path, image_name+'.txt')\n",
        "  file = open(save_path, 'w')\n",
        "\n",
        "  for i, form_character_probs in enumerate(character_probs):\n",
        "    for j, line_character_probs in enumerate(form_character_probs):\n",
        "        decoded_line_bs = get_beam_search(line_character_probs)\n",
        "        print(decoded_line_bs)\n",
        "        file.write(decoded_line_bs + ' ')\n",
        "  file.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zERTmWu0zyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#main code\n",
        "\n",
        "MAX_IMAGE_SIZE_FORM = (1120, 800)\n",
        "MAX_IMAGE_SIZE_LINE = (60, 800)\n",
        "MAX_IMAGE_SIZE_WORD = (30, 140)\n",
        "\n",
        "img_dir = \"/content/drive/My Drive/00_MY Projects and courses/HTR/MXnet/dataset/small\"\n",
        "# img_dir = \"/content/drive/My Drive/00_MY Projects and courses/HTR/MXnet/handwritten-text-recognition-for-apache-mxnet/dataset/custom\"\n",
        "img_names = os.listdir(img_dir)\n",
        "folder_path = os.path.abspath('output')\n",
        "if(not os.path.exists(folder_path)):\n",
        "  print(\"creating dir\")\n",
        "  os.mkdir(folder_path)\n",
        "\n",
        "for img_n in img_names[:4]:\n",
        "  print(img_n)\n",
        "  print(\"\\n New image starting\\n\")\n",
        "  generate_op(img_n,folder_path)\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd0uY4nPkF21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! python HTR.py \"/content/drive/My Drive/00_MY Projects and courses/HTR/MXnet/dataset/small\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7x7unmyTxLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}